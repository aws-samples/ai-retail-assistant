{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efcdbff-e85c-45f2-8230-b075914664e4",
   "metadata": {},
   "source": [
    "# 4. Augmenting retail user interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b1135-d872-4638-ae33-b3c0502b331f",
   "metadata": {},
   "source": [
    "This notebook contains individual sections to construct functions that could act as independent extensions of the basic functionalities described in notebook 3, addressing more commonly observed scenarios encountered in retail user interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e3714-ae6e-4206-b84c-2100eab652c8",
   "metadata": {},
   "source": [
    "4.0. [Set up](#4.0)\n",
    "\n",
    "4.1. [Test and use the Bedrock Knowledge Base Retrieve API](#4.1)\n",
    "\n",
    "4.2. [Augment query context using web search](#4.2)\n",
    "\n",
    "4.3. [Use LLM to generate prompts for creating user-authored content](#4.3)\n",
    "\n",
    "4.4. [Product review analysis](#4.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2f1c4-e8b9-4401-aeac-1dace17b4b0e",
   "metadata": {},
   "source": [
    "## <a id=\"4.0\">Set up<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268a4a0-4055-49f5-918b-79acfc5ac280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to upgrade to the latest version of boto3 if required, and restart the kernel\n",
    "!pip install --upgrade --force --quiet botocore boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06db9d0-3833-4ee5-bed3-5270dced0eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee5ac5-1431-470e-96f9-66eefa71a637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472fa0e-c150-499b-b598-1377ecd08246",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "IMPORTANT! Please copy and paste the required information for your <b>RDS Aurora PostgreSQL database</b> in the cell below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a021f9-ea9c-4bc8-8dc4-33bb8a5ed1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = sess.boto_region_name\n",
    "accountid = sess.account_id()\n",
    "product_db_data_path = 'amazon-reviews-fashion-metadata'\n",
    "bedrock_kb_data_path = 'bedrock-kb-data'\n",
    "bedrock_kb_datasource_uri = f's3://{bucket}/{bedrock_kb_data_path}/'\n",
    "\n",
    "database_identifier='<TODO>'\n",
    "database_arn='<TODO>'\n",
    "database_secret_arn='<TODO>'\n",
    "database_name='<TODO>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a7251-d8a3-4a14-9ec6-d3474710f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ebe170-b9d2-40e1-a30e-c44601f4bcf4",
   "metadata": {},
   "source": [
    "## 4.1 <a id=\"4.1\">Test and use the Bedrock Knowledge Base Retrieve API<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edec6a-c785-47d2-be0d-c147ccbb1437",
   "metadata": {},
   "source": [
    "### Run a test query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6b466-cb77-4e04-8416-1c684fb0ca9a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "IMPORTANT! Please copy and paste the <b>Bedrock Knowledge Base ID</b> for the knowledge base that you are using in the cell below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44c539-050f-4596-bfef-71c9904f08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_kb_id = '<TODO>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b143c8-6be5-444f-bf72-f321832177c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.bedrockkb import bedrock_kb_retrieve\n",
    "\n",
    "search_query = 'shirts with buttons'\n",
    "no_kb_results = 3\n",
    "search_list = bedrock_kb_retrieve(bedrock_kb_id, search_query, no_kb_results)\n",
    "search_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9877b7-4eb9-46f9-9a89-0f6d43ec774c",
   "metadata": {},
   "source": [
    "### Import functions created in other Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53389866-90ca-465e-9e0a-29456dd747dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.getasinlist import get_asin_list\n",
    "from util.gallery import gallery\n",
    "from util.imagehelpers import *\n",
    "from util.pickimg import pick_img\n",
    "from util.refinequery import refine_query\n",
    "from util.getinfo import get_info_from_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e982f-5ceb-4538-9738-716047b456dd",
   "metadata": {},
   "source": [
    "## 4.2 <a id=\"4.2\">Augment query context using web search<a>\n",
    "\n",
    "This section creates a function to search the web when a user query is related to a recent event and/or popular culture that the LLM has not been trained on. The added context from the web search results are used in generating the query for the vector database (the Amazon Bedrock knowledge base)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b72a45-c071-46a6-9f23-ded1596991cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Note: run the next cell twice and/or restart the kernel to fix any <span style=\"color:red\">ERRORS</span>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd1b90-28fb-43d5-a3f2-6904b87d15e6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet langchain duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0e4e8-605f-47a3-8c16-c721c35c6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile util/websearch.py\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "def web_search(web_search_query, log_level='ERROR'):\n",
    "    \n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(max_results=1)\n",
    "    ddg_search = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "    results = ddg_search.run(f'{web_search_query}')\n",
    "    \n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    system_prompt = \"\"\"Your task is to help the user find the most trendy fashion apparel that they would like and convert it into a pgvector text query.\n",
    "Please use the USER SEARCH and WEB RESULTS to output only apparel-related key terms. Do not explain or output anything else. \n",
    "Enhance the key terms by checking that they align with information inferred from user input about the age group, gender, color, material etc.\n",
    "Do not assume or hallucinate. \"\"\"\n",
    "    body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0,\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"USER SEARCH: {web_search_query}\"\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"nWEB RESULTS: {str(results)}\"\n",
    "            }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "    })\n",
    "    \n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "    response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())['content'][0]['text']\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9a852-474f-4e97-8dec-08f98939467d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.websearch import web_search\n",
    "\n",
    "web_search_query=web_search('what should I wear to a Ultra 2024')\n",
    "print(web_search_query)\n",
    "search_asin = get_asin_list(bedrock_kb_retrieve(bedrock_kb_id, web_search_query, no_kb_results))[0]\n",
    "asin_result = get_info_from_db(search_asin, database_arn, database_secret_arn, database_name)\n",
    "asin_result['image'] = pick_img(asin_result['title'], asin_result['image'])\n",
    "print(asin_result)\n",
    "gallery([asin_result['image']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aefaeb-cd6b-4caf-af93-a51e69386c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "web_search_query=web_search('what should I wear to a Harry Styles concert?')\n",
    "print(web_search_query)\n",
    "search_asin = get_asin_list(bedrock_kb_retrieve(bedrock_kb_id, web_search_query, no_kb_results))[0]\n",
    "asin_result = get_info_from_db(search_asin, database_arn, database_secret_arn, database_name)\n",
    "asin_result['image'] = pick_img(asin_result['title'], asin_result['image'])\n",
    "print(asin_result)\n",
    "gallery([asin_result['image']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e41d5-2da5-41aa-8fdd-26d8bbb95c17",
   "metadata": {},
   "source": [
    "## 4.3 <a id=\"4.3\">Use LLM to generate prompts for creating user-authored content<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0472d975-1b92-4b96-a7e8-ed3660058b97",
   "metadata": {},
   "source": [
    "The following function uses the RDS data API to retrieve product description information, which is then fed into an LLM to create a custom message for sharing about the product. This can be used as an initial prompt in writing user previews and/or for users to share products with their friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3a464-9954-4dd2-be4e-865c603cd30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile util/sendmsg.py\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "from util.imagehelpers import * \n",
    "\n",
    "def get_desc_from_db(asin, database_arn, database_secret_arn, database_name):\n",
    "\n",
    "    query=(\n",
    "        f\"SELECT description FROM products WHERE asin='{asin}';\")\n",
    "\n",
    "    rdsdata = boto3.client('rds-data')\n",
    "\n",
    "    response = rdsdata.execute_statement(\n",
    "        resourceArn=database_arn,\n",
    "        secretArn=database_secret_arn,\n",
    "        sql=query,\n",
    "        database=database_name,\n",
    "    )\n",
    "    \n",
    "    description = response['records'][0][0]['stringValue']\n",
    "        \n",
    "    return description\n",
    "\n",
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "# model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "def send_message(product, database_arn, database_secret_arn, database_name, log_level='ERROR'):\n",
    "    \n",
    "    asin = product['asin'].strip('\"')\n",
    "    title = product['title']\n",
    "    image = product['image']\n",
    "    \n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "                             \n",
    "    desc = str(get_desc_from_db(asin, database_arn, database_secret_arn, database_name))\n",
    "    \n",
    "    content = [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"PRODUCT TITLE: {title}\" \n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"PRODUCT DESCRIPTION: {desc}\" \n",
    "                    }\n",
    "                ]\n",
    "                             \n",
    "    img_list = filter_image_url(image)\n",
    "    if img_list:\n",
    "        for img in img_list:\n",
    "            image_data = get_base64_from_bytes(url_image_processing(img))\n",
    "            content.append({\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": image_data,\n",
    "                            }\n",
    "            })\n",
    "        \n",
    "    messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "    }]\n",
    "    \n",
    "    system_prompt = \"\"\"Your task is to help the user generate a short message to tell others about the product using the text and image inputs. \n",
    "    Generate only a short summarized message from first-person perspective.\"\"\"\n",
    "    body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 100,\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\": messages\n",
    "    })\n",
    "    \n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "    response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())['content'][0]['text']\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003d771-9664-415f-91e1-418b4424dd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.sendmsg import send_message\n",
    "\n",
    "message = send_message(asin_result, database_arn, database_secret_arn, database_name)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e30073-06f5-4d34-8087-4728f2c196bf",
   "metadata": {},
   "source": [
    "## 4.4 <a id=\"4.4\">Product review analysis<a>\n",
    "\n",
    "To provide end users with the best retail experience, it is important to understand their feedback at scale. This section provides some examples to perform NLP (Natural Language Processing) tasks on user-written reviews easily with LLMs without the need to fine-tune and/or train conventional NLP classification and/or topic modelling models. \n",
    "\n",
    "The added benefits of using LLMs include the ability to already comprehend sentiment accurately as LLMs have been trained on large datasets, and the ability to adapt to a variety of preferred output formats and/or themes. With the LLM's ability to be open-ended, we would also need to steer the LLM to our preferred output to achieve some level of predictability and consistency for further parsing and processing (e.g. creating charts).\n",
    "    \n",
    "This section brings you through the analysis of reviews from the Amazon Reviews dataset available [here](https://amazon-reviews-2023.github.io/). The exact dataset used is the 5-core fashion review dataset from 2018 to select a sufficiently small dataset size for this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f4b32-6963-445f-a62d-550d4b8e5f3d",
   "metadata": {},
   "source": [
    "### Download fashion reviews dataset (5-core) and perform basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466d167-0f1a-4c3a-b62d-3af8598da4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -O https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/AMAZON_FASHION_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ffa80-9ad6-4ab9-9158-949da47b069b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_json('AMAZON_FASHION_5.json.gz',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe9d53c-e8b1-463c-a849-5111237579b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = dataframe[['asin','overall','reviewText']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40114449-3ac9-448b-b376-684ee4c049c5",
   "metadata": {},
   "source": [
    "### 4.4.0 Extract topics from reviews (zero-shot)\n",
    "Create a function to perform open-ended topic analysis from reviews. This uses a test prompt to understand the base model's ability to adapt to new formats and/or be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad341a-a776-4f80-9b62-27deef729ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "def topictest(review, log_level='ERROR'):\n",
    "    \n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Your role is to extract topics from the review as a JSON array. Do not output anything else.\"\"\"\n",
    "    body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0,\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"<review>\\n {review}\\n</review>\"\n",
    "            }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "    })\n",
    "    \n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "    response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())['content'][0]['text']\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130aa3e-0b6b-4b71-84dc-34580c949d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Take first 5 reviews only\n",
    "reviews = reviews[:5]\n",
    "\n",
    "review_analysis = []\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    print('Analyzing review', index)\n",
    "    analysis = topictest(row['reviewText'])\n",
    "    review_analysis.append(analysis)\n",
    "    \n",
    "analyzed_reviews = reviews.assign(review_tags=review_analysis)\n",
    "analyzed_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddf7ce-31be-477f-a693-a3b79e56d8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4.1 Extract topics from reviews (one-shot)\n",
    "Create a function to perform open-ended topic extraction from reviews for further classification and clustering purposes. In the prompt, we provide a single example for the LLM to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a146044-c858-4aa2-ab52-2a35ce4977f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile util/reviews_topicextract.py\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "def topicextract(review, log_level='ERROR'):\n",
    "    \n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Your only task is to extract topics from product reviews as JSON Arrays. Do not output anything else.\n",
    "Example:\n",
    "user: <review>\\n Best exercise shorts ever! The material breathes perfectly on hot summer days. It's also highly durable and its brightness does not fade after washes.\\n</review>\n",
    "assistant: [material, quality, color]\"\"\"\n",
    "    body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0,\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"<review>\\n {review}\\n</review>\"\n",
    "            }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "    })\n",
    "    \n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "    response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())['content'][0]['text']\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016275d-4d56-4134-ac78-05dad25de0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.reviews_topicextract import topicextract\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Take first 5 reviews only\n",
    "reviews = reviews[:5]\n",
    "\n",
    "review_analysis = []\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    print('Analyzing review', index)\n",
    "    analysis = topicextract(row['reviewText'])\n",
    "    review_analysis.append(analysis)\n",
    "    \n",
    "analyzed_reviews = reviews.assign(review_tags=review_analysis)\n",
    "analyzed_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca6463-9714-48c5-84fc-8fb5ae7554d1",
   "metadata": {},
   "source": [
    "### 4.4.2 Extract topic and the corresponding sentiment from reviews (few-shot)\n",
    "Create a function to perform open-ended topic extraction and target-sentiment analysis from reviews for further classification and clustering purposes. This also helps merchants efficiently analyze feedback for product improvement. In the prompt, we provide only a three examples for the LLM to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec509e37-67bc-4d06-8eba-8313520b5949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile util/reviews_topicsentiment.py\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "def topicsentiment(review, log_level='ERROR'):\n",
    "    \n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Identify the targets in the product REVIEW, and the writer's stance towards the target from options: positive / negative / neutral. \n",
    "Extract this in the form of a JSON Array with format [{{target:stance}},{{target:stance}}]. Output only the JSON Array and do not return anything else.\n",
    "user: <review>\\n I thought that this was not bad.\\n</review>\n",
    "assistant: [{{\"quality\": \"neutral\"}}]\n",
    "\n",
    "user: <review>\\n Not the best.\\n</review>\n",
    "assistant: [{{\"quality\": \"negative\"}}]\n",
    "\n",
    "user: <review>\\n I hate how the packaging is so difficult to remove and the colors are so ugly. But aside from that, the quality is excellent.\\n</review>\n",
    "assistant: [{{\"packaging\": \"negative\"}}, {{\"color\": \"negative\"}}, {{\"quality\": \"positive\"}}]\"\"\"\n",
    "    body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0,\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"<review>\\n {review}\\n</review>\"\n",
    "            }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "    })\n",
    "    \n",
    "    bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "    response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())['content'][0]['text']\n",
    "\n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd7d72-03dd-4518-a92b-225bc18b3be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.reviews_topicsentiment import topicsentiment\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Take first 5 reviews only\n",
    "reviews = reviews[:5]\n",
    "\n",
    "review_analysis = []\n",
    "\n",
    "for index, row in reviews.iterrows():\n",
    "    print('Analyzing review', index)\n",
    "    analysis = topicsentiment(row['reviewText'])\n",
    "    review_analysis.append(analysis)\n",
    "    \n",
    "analyzed_reviews = reviews.assign(review_tags=review_analysis)\n",
    "analyzed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b79fd57-4874-47b0-940d-fcfba2939311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
